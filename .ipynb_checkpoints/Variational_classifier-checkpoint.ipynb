{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Quantum Classifier is a quantum circuit that can be trained from original labelled data to classify new data samples. First we will classify simple parity function, then move on to more complicated iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import torch\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "from pennylane.operation import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classifying Parity function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parity function takes in 4 bits and returns 1(0) when there is odd(even) number of 1. We start by loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [0. 0. 0. 0.], Y = -1\n",
      "X = [0. 0. 0. 1.], Y =  1\n",
      "X = [0. 0. 1. 0.], Y =  1\n",
      "X = [0. 0. 1. 1.], Y = -1\n",
      "X = [0. 1. 0. 0.], Y =  1\n",
      "X = [0. 1. 0. 1.], Y = -1\n",
      "X = [0. 1. 1. 0.], Y = -1\n",
      "X = [0. 1. 1. 1.], Y =  1\n",
      "X = [1. 0. 0. 0.], Y =  1\n",
      "X = [1. 0. 0. 1.], Y = -1\n",
      "X = [1. 0. 1. 0.], Y = -1\n",
      "X = [1. 0. 1. 1.], Y =  1\n",
      "X = [1. 1. 0. 0.], Y = -1\n",
      "X = [1. 1. 0. 1.], Y =  1\n",
      "X = [1. 1. 1. 0.], Y =  1\n",
      "X = [1. 1. 1. 1.], Y = -1\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"parity.txt\")\n",
    "X = np.array(data[:,:-1], requires_grad = False)\n",
    "Y = np.array(data[:, -1], requires_grad = False)\n",
    "Y = Y * 2 - np.ones(len(Y))\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print('X = {}, Y = {: d}'.format(X[i], int(Y[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(W):\n",
    "    qml.Rot(*W[0], wires = 0)\n",
    "    qml.Rot(*W[1], wires = 1)\n",
    "    qml.Rot(*W[2], wires = 2)\n",
    "    qml.Rot(*W[3], wires = 3)\n",
    "    \n",
    "    qml.CNOT(wires = [0,1])\n",
    "    qml.CNOT(wires = [1,2])\n",
    "    qml.CNOT(wires = [2,3])\n",
    "    qml.CNOT(wires = [3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statepreparation(x):\n",
    "    qml.BasisState(x, wires = [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires = 4)\n",
    "\n",
    "@qml.qnode(dev, interface = \"torch\")\n",
    "def circuit(weights, x):\n",
    "    statepreparation(x)\n",
    "    for W in weights:\n",
    "        layer(W)\n",
    "    \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Variational_classifier(var, x):\n",
    "    weights = var[0]\n",
    "    bias = var[1]\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define square_loss as our cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "    loss = loss / len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(var, X, Y):\n",
    "    predictions = [Variational_classifier(var, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    accuracy = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            accuracy = accuracy + 1\n",
    "    accuracy = accuracy /len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we optimize the circuit,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "num_qubits = 4\n",
    "num_layers = 2\n",
    "steps = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity_circuit_optimize(num_layers, steps):\n",
    "    \n",
    "    var = (0.01 * np.random.randn (num_layers, num_qubits, 3), 0.0)\n",
    "    print(var)\n",
    "    var_torch = torch.tensor(var, requires_grad = True)\n",
    "    \n",
    "    opt = NesterovMomentumOptimizer(0.5)\n",
    "    batch_size = 5\n",
    "    \n",
    "    for i in range(steps):\n",
    "        \n",
    "        batch_index = np.random.choice(len(X), size = batch_size)\n",
    "        \n",
    "        X_batch = X[batch_index]\n",
    "        Y_batch = Y[batch_index]\n",
    "        \n",
    "        X_batch_torch = torch.tensor(X_batch_torch, requires_grad = False)\n",
    "        Y_batch_torch = torch.tensor(Y_batch_torch, requires_grad = False)\n",
    "        \n",
    "        var = opt.step(cost(var, X, Y), var)\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            x = X[i]\n",
    "            pred = variational_classifier(var, x)\n",
    "            predictions.append(pred)\n",
    "        acc = accuracy(Y, predictions)\n",
    "        \n",
    "        print(\"Steps: \", i, \"Cost: \", cost(var, X, Y), \"Accuracy: \", acc)\n",
    "        return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 0.02269755, -0.01454366,  0.00045759],\n",
      "         [-0.00187184,  0.01532779,  0.01469359],\n",
      "         [ 0.00154947,  0.00378163, -0.00887786],\n",
      "         [-0.01980796, -0.00347912,  0.00156349]],\n",
      "\n",
      "        [[ 0.01230291,  0.0120238 , -0.00387327],\n",
      "         [-0.00302303, -0.01048553, -0.01420018],\n",
      "         [-0.0170627 ,  0.01950775, -0.00509652],\n",
      "         [-0.00438074, -0.01252795,  0.0077749 ]]], requires_grad=True), 0.0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b8bf96f69bd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvar_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparity_circuit_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-a3799dab69a9>\u001b[0m in \u001b[0;36mparity_circuit_optimize\u001b[0;34m(num_layers, steps)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_qubits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvar_torch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNesterovMomentumOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "var_trained = parity_circuit_optimize(num_layers, steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
